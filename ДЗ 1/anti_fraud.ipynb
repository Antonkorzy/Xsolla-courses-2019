{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "anti-fraud.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFp7F5c4rxj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGzSjXeJrxj_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "4bd75188-9bdb-4c28-b93e-6295b6fa9799"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "from sklearn.model_selection import StratifiedShuffleSplit,train_test_split,cross_val_score,StratifiedKFold,GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTEENN\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,auc\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZL_dZ4vrxkS",
        "colab_type": "text"
      },
      "source": [
        "# Попробуем решить ML часть задачи разработки anti-fraud системы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAPDY0oYrxkV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6139ca13-3516-45c6-9d96-914320990ed5"
      },
      "source": [
        "GeneralDataFrame = pd.read_csv('./creditcard.csv')\n",
        "GeneralDataFrame.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284807, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RhPdnXArxkd",
        "colab_type": "code",
        "colab": {},
        "outputId": "56140fd8-2bfe-4a5f-85df-0d06b1c9dd94"
      },
      "source": [
        "GeneralDataFrame.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLStzHAcrxkq",
        "colab_type": "code",
        "colab": {},
        "outputId": "49d85341-992a-48b1-9af0-613b5845cdaf"
      },
      "source": [
        "GeneralDataFrame.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>3.919560e-15</td>\n",
              "      <td>5.688174e-16</td>\n",
              "      <td>-8.769071e-15</td>\n",
              "      <td>2.782312e-15</td>\n",
              "      <td>-1.552563e-15</td>\n",
              "      <td>2.010663e-15</td>\n",
              "      <td>-1.694249e-15</td>\n",
              "      <td>-1.927028e-16</td>\n",
              "      <td>-3.137024e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.537294e-16</td>\n",
              "      <td>7.959909e-16</td>\n",
              "      <td>5.367590e-16</td>\n",
              "      <td>4.458112e-15</td>\n",
              "      <td>1.453003e-15</td>\n",
              "      <td>1.699104e-15</td>\n",
              "      <td>-3.660161e-16</td>\n",
              "      <td>-1.206049e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Time            V1            V2            V3            V4  \\\n",
              "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
              "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
              "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
              "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
              "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
              "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
              "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
              "\n",
              "                 V5            V6            V7            V8            V9  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
              "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
              "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
              "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
              "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
              "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
              "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
              "\n",
              "       ...           V21           V22           V23           V24  \\\n",
              "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
              "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
              "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
              "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
              "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
              "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
              "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
              "\n",
              "                V25           V26           V27           V28         Amount  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
              "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
              "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
              "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
              "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
              "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
              "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
              "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
              "\n",
              "               Class  \n",
              "count  284807.000000  \n",
              "mean        0.001727  \n",
              "std         0.041527  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         0.000000  \n",
              "max         1.000000  \n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OheL-DXtrxk1",
        "colab_type": "text"
      },
      "source": [
        "В нашем распоряжении есть набор данных, в котором около 300к записей транзакций по банковским картам. Судя по тому, что мы видим первым взглядом, можно говорить о том что наши данные уже стандартизированы, все поля кроме Amount. Имеем 2 метки классов 0 - NotFraud, 1 - Fraud, целевой класс, который будем пытаться предсказывать - Fraud.\n",
        "Заметим еще то, что данные у нас анонимные, это связано со спецификой решаемой задачи, финансовые данные как и медицинские должны быть защещены путем анонимизации, если вы конечно не чей-то личный врач или банкир."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n98nla3yrxk3",
        "colab_type": "text"
      },
      "source": [
        "Как говорилось ранее в лекции, особенность задачи anti-fraud заключается в том, что скорее всего мы будем работать с несбалансированными по классам выборками. Чаще всего хороших транзакций гораздо больше чем мошеннических, потому что каждый участник процесса формирования и обработки транзакций на своей стороне пытается снизить количество фродовых транзакций, да и в принципе мошенников меньше чем нормальных людей, поэтому работаем с тем что есть."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXyk4q2xrxk4",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим, можем нам повезло и у нас классы сбалансированы:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_WOpulprxk6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "282d4a84-b961-4819-afeb-7277bc91238d"
      },
      "source": [
        "Names = {0:'Not_Fraud',1:'Fraud'}\n",
        "print(GeneralDataFrame.Class.value_counts().rename(index = Names))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not_Fraud    284315\n",
            "Fraud           492\n",
            "Name: Class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN_MXU4trxlE",
        "colab_type": "text"
      },
      "source": [
        "Увы, конечно же они не будут сбалансированы, ничего удивительного, причем в нашем случае расхождение в количестве ппримеров каждого класса очень сильное, в несколько порядков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk6QCaxmrxlG",
        "colab_type": "text"
      },
      "source": [
        "Разделим наш набор данных на предикторы и целевую перменную, которую будем пытаться предсказывать. Избавимся от столбца Time, в данном случае мы не пытаемся решить задачу прогнозирования временных рядов, поэтому информации для нас в этой переменной не так уж и много."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJVqVADprxlI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "1413be7d-be38-4939-c390-853ab24ba319"
      },
      "source": [
        "FeatureNames = GeneralDataFrame.iloc[:,1:30].columns\n",
        "Target = GeneralDataFrame.iloc[:1,30:].columns\n",
        "print(FeatureNames)\n",
        "print(Target)\n",
        "\n",
        "DataFeatures = GeneralDataFrame[FeatureNames]\n",
        "DataTarget = GeneralDataFrame[Target]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
            "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
            "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
            "      dtype='object')\n",
            "Index(['Class'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6hAcey2rxlP",
        "colab_type": "text"
      },
      "source": [
        "Мы изначально заметили дисбаланс классов, уже сходу понимаем что строить классификатор на таких данных это не очень хорошая идея, потому что мы скорее всего получим ситуацию переобучения модели под конкретный класс (под тот класс примеров которого больше). Но все же чисто в исследовательских целях обучим какой-нибудь простой алгоритм типа логистической регрессии, просто для понимания того, о чего будем отталкиваться в плане точности классификации."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfU0vVQorxlX",
        "colab_type": "code",
        "colab": {},
        "outputId": "b227a3a4-9fb3-4a8f-f98f-9b4a68e47018"
      },
      "source": [
        "#разбиваем генеральную выборку на тренировочную - 70% и тестовую - 30%\n",
        "Splitter = StratifiedShuffleSplit(n_splits = 1,test_size = 0.3,random_state = 40)\n",
        "for train_indices,test_indices in Splitter.split(DataFeatures,DataTarget):\n",
        "    XTrain,YTrain = DataFeatures.iloc[train_indices],DataTarget.iloc[train_indices]\n",
        "    XTest,YTest = DataFeatures.iloc[test_indices],DataTarget.iloc[test_indices]\n",
        "\n",
        "print('x_test:' + str(len(XTrain)) + '  y_test:' + str(len(YTrain)))\n",
        "print('x_train:' + str(len(XTest)) + '  y_train:' + str(len(YTest)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test:199364  y_test:199364\n",
            "x_train:85443  y_train:85443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5FL6d9Orxlf",
        "colab_type": "code",
        "colab": {},
        "outputId": "721867be-0052-43bd-ed14-d4c680180f3d"
      },
      "source": [
        "#проверим что там у нас с балансами классов\n",
        "def CheckClassesBalance(Data):\n",
        "    Fraud_Train = []\n",
        "    NotFraud_Train = []\n",
        "    \n",
        "    for i in Data:\n",
        "        if i == 1:\n",
        "            Fraud_Train.append(i)\n",
        "        else:\n",
        "            NotFraud_Train.append(i)\n",
        "        \n",
        "    print('Number of training elements fraud class: ' + str(len(Fraud_Train)))\n",
        "    print('Number of training elements not fraud class: ' + str(len(NotFraud_Train)))\n",
        "\n",
        "Y = YTrain['Class']\n",
        "CheckClassesBalance(Y)\n",
        "\n",
        "Y = YTest['Class']\n",
        "CheckClassesBalance(Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training elements fraud class: 344\n",
            "Number of training elements not fraud class: 199020\n",
            "Number of training elements fraud class: 148\n",
            "Number of training elements not fraud class: 85295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ohT1LWirxlm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a2001518-9669-4c0b-8b3d-52724b02dea4"
      },
      "source": [
        "#либо еще такой вариант есть, кому как нравится, результат разбиения на выборки будет одинаковый\n",
        "XTrain,XTest,YTrain,YTest = train_test_split(DataFeatures,DataTarget,#stratify = DataTarget,\n",
        "                                             test_size = 0.3,\n",
        "                                             random_state = 40)\n",
        "\n",
        "print('x_test:' + str(len(XTrain)) + '  y_test:' + str(len(YTrain)))\n",
        "print('x_train:' + str(len(XTest)) + '  y_train:' + str(len(YTest)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test:199364  y_test:199364\n",
            "x_train:85443  y_train:85443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I43MJKyrxlt",
        "colab_type": "code",
        "colab": {},
        "outputId": "7fc80b9e-5c5a-4866-b97e-e7c9f2a343f3"
      },
      "source": [
        "Y = YTrain['Class']\n",
        "CheckClassesBalance(Y)\n",
        "\n",
        "Y = YTest['Class']\n",
        "CheckClassesBalance(Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training elements fraud class: 344\n",
            "Number of training elements not fraud class: 199020\n",
            "Number of training elements fraud class: 148\n",
            "Number of training elements not fraud class: 85295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBFR1_cbrxl4",
        "colab_type": "code",
        "colab": {},
        "outputId": "693c0672-78ad-4f2b-92dd-074292752129"
      },
      "source": [
        "pd.unique(YTrain['Class'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrjxEeQLrxmH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bc952495-d7a0-4753-84c5-f42d6c950ab5"
      },
      "source": [
        "#Формируем веса для переменных\n",
        "from sklearn.utils import compute_class_weight\n",
        "w = compute_class_weight('balanced', np.unique(YTrain), YTrain['Class'])\n",
        "weights = {\n",
        "     np.unique(YTrain)[0] : w[0], # class 0 with weight 0\n",
        "     np.unique(YTrain)[1] : w[1]  # class 1 with weight 1 \n",
        "}\n",
        "print(weights) #веса"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 0.5008894025425858, 1: 281.5875706214689}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lQYRewgrxmd",
        "colab_type": "text"
      },
      "source": [
        "![%D0%A1%D0%BD%D0%B8%D0%BC%D0%BE%D0%BA%20%D1%8D%D0%BA%D1%80%D0%B0%D0%BD%D0%B0%202019-07-26%20%D0%B2%2011.32.59.png](attachment:%D0%A1%D0%BD%D0%B8%D0%BC%D0%BE%D0%BA%20%D1%8D%D0%BA%D1%80%D0%B0%D0%BD%D0%B0%202019-07-26%20%D0%B2%2011.32.59.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsB4R6mkrxoG",
        "colab_type": "text"
      },
      "source": [
        "# Обучение классификатора на ансамблевом алгоритме случайного леса деревьев решений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veAzqcuXrxoJ",
        "colab_type": "text"
      },
      "source": [
        "Как и в случае использования алгоритма логистической регрессии для разработки бинарного классификатора карточных транзакций, попробуем обучиться на несбалансированных данных с помощью алгоритма случайного леса на минималках. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4QrUTccrxoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "03631cfd-6d69-4780-e0a2-a51bfc398662"
      },
      "source": [
        "#провалидируем классификатор с помощью кросс-валидации на 5 фолдах с расчетом среднего значения точности\n",
        "SKF = StratifiedKFold(n_splits = 5,shuffle = True,random_state = 40)\n",
        "RFC = RandomForestClassifier()\n",
        "Results = cross_val_score(RFC,XTrain,YTrain,cv = SKF)\n",
        "print(\"CV accuracy score: {:.2f}%\".format(Results.mean()*100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CV accuracy score: 99.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL3fQ5IfrxoT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "53271873-2f79-4177-a333-1ed2049f1534"
      },
      "source": [
        "#обучаем на полной тренировочной выборке\n",
        "Model_RFC_RandSeed = np.random.RandomState(40)\n",
        "\n",
        "Model_RFC = RandomForestClassifier(random_state = Model_RFC_RandSeed, class_weight=weights, \n",
        "                                   n_estimators=50, max_depth=50, min_samples_leaf=2)\n",
        "Model_RFC.fit(XTrain,YTrain)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True,\n",
              "                       class_weight={0: 0.5008894025425858,\n",
              "                                     1: 281.5875706214689},\n",
              "                       criterion='gini', max_depth=50, max_features='auto',\n",
              "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
              "                       min_impurity_split=None, min_samples_leaf=2,\n",
              "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                       n_estimators=50, n_jobs=None, oob_score=False,\n",
              "                       random_state=<mtrand.RandomState object at 0x7fb49294e0d8>,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r9hRIYgrxoZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "856b1408-2068-4349-9000-fbad6eccdf5f"
      },
      "source": [
        "#проверим работоспособность нашего классификатора на тестовой выборке\n",
        "Pred = Model_RFC.predict(XTest)\n",
        "print(classification_report(YTest,Pred,digits=5))\n",
        "\n",
        "ClassNames = ['NotFraud','Fraud']\n",
        "Matrix = confusion_matrix(YTest,Pred)\n",
        "DFCM = pd.DataFrame(Matrix,index = ClassNames, columns = ClassNames)\n",
        "sns.heatmap(DFCM,annot = True,cbar = None,cmap = \"Blues\",fmt = 'g')\n",
        "plt.title(\"Confusion Matrix\"),plt.tight_layout()\n",
        "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
        "plt.show()\n",
        "\n",
        "PredProbaClass = Model_RFC.predict_proba(XTest)[:,1]\n",
        "fpr,tpr,_ = roc_curve(YTest,PredProbaClass)\n",
        "roc_auc = auc(fpr,tpr)\n",
        "plt.plot(fpr,tpr,label = 'area = %.2f' %roc_auc)\n",
        "plt.plot([0, 1],[0, 1],'k--')\n",
        "plt.xlim([0.0,1.0])\n",
        "plt.ylim([0.0,1.05])\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99967   0.99994   0.99981     85305\n",
            "           1    0.95652   0.79710   0.86957       138\n",
            "\n",
            "    accuracy                        0.99961     85443\n",
            "   macro avg    0.97810   0.89852   0.93469     85443\n",
            "weighted avg    0.99960   0.99961   0.99960     85443\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEmCAYAAAAOb7UzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHaNJREFUeJzt3Xm4VmW9//H3F1BBQHAAPE4pmvMs\netSOJR6HTNT0mGaYpXb8Odcxx/SYQ1nq0cy0TlqnQRwazHJKK8pK1NRIAdMsU1NRUARRcGD4/v5Y\na9PDlr33w2avvXHxfl3Xc7meNd3fB/fmw32v9dwrMhNJkuqiV08XIElSVzLYJEm1YrBJkmrFYJMk\n1YrBJkmqFYNNklQrBpvUCRHRLyJujYhXI+JHS3Ce0RHxi66srSdExM8j4hM9XYcEBptqLiI+FhEP\nRcTrEfFC+Rfwv3XBqQ8ChgGrZuZHOnuSzLwuM/fsgnoWEhG7RkRGxM2t1m9Vrr+7yfOcGxFjOtov\nM/fOzO91slypSxlsqq2IOBm4HLiQIoTWAb4O7N8Fp38P8ERmzu2Cc1XlJWCniFi1Yd0ngCe6qoEo\n+PeIlir+QKqWImIQcD5wfGb+JDNnZeaczLw1M08t91khIi6PiMnl6/KIWKHctmtEPBcRn42IqWVv\n74hy23nAOcAhZU/wqNY9m4hYt+wZ9SnffzIi/h4Rr0XEUxExumH9PQ3H7RwRD5ZDnA9GxM4N2+6O\niAsiYlx5nl9ExGrt/DG8DfwU+Gh5fG/gEOC6Vn9WX42IZyNiZkT8MSJ2Kdd/EPhcw+d8pKGOL0bE\nOGA2MLxc96ly+zci4qaG818UEWMjIpr+HygtAYNNdbUT0Be4uZ19zgJ2BLYGtgJ2AM5u2L46MAhY\nEzgKuCoiVs7Mz1P0An+QmQMy89vtFRIR/YErgL0zcyCwM/DwIvZbBbi93HdV4DLg9lY9ro8BRwBD\ngeWBU9prG/g+cHi5vBcwCZjcap8HKf4MVgGuB34UEX0z885Wn3OrhmM+DhwNDASeaXW+zwJblKG9\nC8Wf3SfS+fvUTQw21dWqwMsdDBWOBs7PzKmZ+RJwHsVf2C3mlNvnZOYdwOvARp2sZz6weUT0y8wX\nMvPRReyzD/DXzLw2M+dm5g3A48C+Dft8JzOfyMw3gB9SBFKbMvNeYJWI2Igi4L6/iH3GZOa0ss1L\ngRXo+HN+NzMfLY+Z0+p8syn+HC8DxgAnZuZzHZxP6jIGm+pqGrBay1BgG9Zg4d7GM+W6BedoFYyz\ngQGLW0hmzqIYAjwGeCEibo+IjZuop6WmNRvev9iJeq4FTgBGsogebEScEhGPlcOfMyh6qe0NcQI8\n297GzPwD8HcgKAJY6jYGm+rqPuAt4MPt7DOZ4iaQFuvwzmG6Zs0CVmx4v3rjxsy8KzP3AP6Fohd2\nTRP1tNT0fCdranEtcBxwR9mbWqAcKjwNOBhYOTMHA69SBBJAW8OH7Q4rRsTxFD2/yeX5pW5jsKmW\nMvNVihs8roqID0fEihGxXETsHREXl7vdAJwdEUPKmzDOoRg664yHgfdHxDrljStntmyIiGERsX95\nre0tiiHN+Ys4xx3AhuVXFPpExCHApsBtnawJgMx8CvgAxTXF1gYCcynuoOwTEecAKzVsnwKsuzh3\nPkbEhsAXgMMohiRPi4h2h0ylrmSwqbbK60UnU9wQ8hLF8NkJFHcKQvGX70PABGAiML5c15m2fgn8\noDzXH1k4jHqVdUwGXqEImWMXcY5pwCiKmy+mUfR0RmXmy52pqdW578nMRfVG7wLupPgKwDPAmyw8\nzNjy5fNpETG+o3bKod8xwEWZ+Uhm/pXizsprW+44laoW3qgkSaoTe2ySpFox2CRJtWKwSZJqxWCT\nJNVKe19e7VH9tjnBu1okYPqDV/Z0CdJSoW8fmppv1B6bJKlWDDZJUq0YbJKkWjHYJEm1YrBJkmrF\nYJMk1YrBJkmqFYNNklQrBpskqVYMNklSrRhskqRaMdgkSbVisEmSasVgkyTVisEmSaoVg02SVCsG\nmySpVgw2SVKtGGySpFox2CRJtWKwSZJqxWCTJNWKwSZJqhWDTZJUKwabJKlWDDZJUq0YbJKkWjHY\nJEm1YrBJkmrFYJMk1YrBJkmqFYNNklQrBpskqVYMNklSrRhskqRaMdgkSbVisEmSasVgkyTVisEm\nSaoVg02SVCsGmySpVgw2SVKtGGySpFox2CRJtWKwSZJqxWCTJNWKwSZJqhWDTZJUKwabJKlWDDZJ\nUq0YbJKkWjHYJEm1YrBJkmrFYJMk1Uqfni5A3ePE0SP55AE7k5k8+rfJHP35MXztrI+yy3Yb8Orr\nbwJw9DnXMuGJ5xm16xacc+wo5mcyd958Trvkx9z78N8BGL3vv3LGp/YC4Mvfuovrbv0DANtssjZX\nn/dx+q2wHHeNe5TPXvzjnvmgUhfbe4/dWLF/f3r36kXvPr254Yc/6emS1AGDbRmwxpBBHHfoB9jm\nP77Im2/NYcxFR/KRvbYD4HOX/5Sbf/XwQvv/5g9/4ba7JwKw+XvXYMxFR7L1gV9g5ZVW5Kyj9+Z9\noy8mM7n3+tO5/e4JzHjtDa743CEcf8H1PDDxaX565bHs+b5N+cW4P3f7Z5Wq8K3vfI+VV16lp8tQ\nkxyKXEb06d2bfissR+/evejXd3leeOnVNved9cbbC5b791uBzGJ5j503Yez9jzN95mxmvPYGY+9/\nnD3ftymrr7YSA/v35YGJTwNw/W0PsO+uW1b5cSSpTZX02CJi2/a2Z+b4KtrVok1+6VUu//5Ynvj5\nBbzx1tuMve9xxt7/OIfsPYJzj9+XM/9zb+5+4C+cfcUtvD1nLgD7jdyS80/cjyGrDOTAk/4XgDWG\nDOa5KdMXnPf5qTNYY8hg1hg6mOenzvjn+ikzWGPo4O79kFJVAo75z6OICA76yCEcdPAhPV2ROlDV\nUOSl5X/7AiOAR4AAtgQeAnZa1EERcTRwNECftXalz2qbVVTesmXwwH6M2nULNhn1eWa8NpvrLz6K\nj35oe8752i28+PJMll+uD1f996F89ojd+dLVdwJwy28mcMtvJvC+bdfnnOP2YZ9jruzhTyH1jO9e\newPDhg1j2rRpHPOpI1hv+HC2G7F9T5eldlQyFJmZIzNzJPACsG1mjsjM7YBtgOfbOe7qct8RhlrX\n2e1fN+bpydN4efrrzJ07n5/++hF23Go9Xnx5JgBvz5nL9392PyM2W/cdx44b/yTrrbkaqw7uz+SX\nZrDWsJUXbFtz6GAmvzSDyVNnsGZDD23NYYOZ3NCDk97Nhg0bBsCqq67KbrvvwaSJE3q4InWk6mts\nG2XmxJY3mTkJ2KTiNtXKsy++wg5brEe/vssBMHKHjfjLU1NYfbWVFuyz38gt+fOTkwEYvvZqC9Zv\nvfFarLB8H6bNmMUv732M3XfamMED+zF4YD9232ljfnnvY7z48kxem/UmO2yxLgAfG7UDt/3WX369\n+82ePZtZs15fsHzfvePYYIP39nBV6kjVd0VOiIhvAWPK96MB/8brZg9Oeoabf/Un7rv+dObOm88j\njz/Ht28ax8+uPJbVVh5IBEz4y3Oc+MUbATjg37fmY6P+lTlz5/HmW3P4+On/B8D0mbP50jV3cs+Y\n0wC48Oo7mT5zNgCf/tIPufq8w+i3wnL8Ytyfuese74jUu98r06bxXycdD8DcefP40D6jeN8u7+/h\nqtSRyJZb3qo4eURf4Fig5Sfhd8A3MvPNjo7tt80J1RUmvYtMf9DrmxJA3z5EM/tV2mMrA+wr5UuS\npMpVGmwR8RTwjp5XZg6vsl1J0rKr6mtsIxqW+wIfAfz6viSpMpXeFZmZ0xpez2fm5cA+VbYpSVq2\nVT0U2TgDSS+KHpzzU0qSKlN1yFzasDwXeBo4uOI2JUnLsKrvihxZ5fklSWqt8mHBiNgH2Izi5hEA\nMvP8qtuVJC2bKr15JCL+FzgEOJFiEuSPAO+psk1J0rKt6rkid87Mw4HpmXkexaz+G1bcpiRpGVZ1\nsLVMnTU7ItYA5gD/UnGbkqRlWNXX2G6NiMHAJcB4illIrqm4TUnSMqyyYIuIXsDYzJwB3BQRtwF9\nM/PVqtqUJKmyocjMnA9c1fD+LUNNklS1qq+xjY2I/4iIph41IEnSkqo62P4f8CPgrYiYGRGvRcTM\nituUJC3Dqp55ZGCV55ckqbVKemwRcULD8mZVtCFJ0qJUNRR5ZMPytRW1IUnSO1R9jQ2KqbQkSeoW\nVV1jGxwRB1AE50oRcWDjxsz8SUXtSpKWcVUF22+B/crl3wH7NmxLwGCTJFWikmDLzCMAImK9zHyq\ncVtErFdFm5IkQfXX2G5axLofV9ymJGkZVkmPLSI2pni46KBW19dWouGBo5IkdbWqrrFtBIwCBrPw\n9bXXgP+sqE1Jkiq7xvYz4GcRsVNm3ldFG5IkLUrV19iejYibI2Jq+bopItaquE1J0jKs6mD7DnAL\nsEb5urVcJ0lSJToMtojYMSJWLJcPjYiLI2LtJs8/NDO/k5lzy9d3gSFLUK8kSe1qpsd2NfBGRGwJ\nnA48T/PzP74cEYdFRO/ydRgwrZO1SpLUoWaCbW5mJrA/cGVmfpXitv1mHAkcDLwIvAAcBBzRmUIl\nSWpGM3dFzoqIU4HDgF0johewXDMnz8xn+OfUWpIkVa6ZYDuEItSOycwXImId4LL2DoiIc9rZnJl5\nwWLUKElS05oJtunA/2Tm/IhYn+LL1x1dY5u1iHX9gaOAVQGDTZJUiWaC7ffA+yNiEPBrYDzwUeDw\ntg7IzEtbliNiIPBpimtrNwKXtnWcJElLqpmbR3pl5mzgP4BvZOYBwFYdHRQRq0TEF4AJFAG6bWae\nnplTl6hiSZLa0VSwRcT2wGjgtmaOi4hLgAcp5obcIjPPzczpS1SpJElNaCbYTgbOA27LzEkRMZxi\neLI9n6WYaeRsYHJEzCxfr0XEzCUrWZKktnV4jS0zf01xba3l/d+B4zo4puqpuiRJWqQOgy0iVqPo\ngW1Gw7PUMnPPCuuSJKlTmulZjQGeBjYELqKYReThCmuSJKnTmgm2IZn5TeDtzBwLfALYtdKqJEnq\npGa+xzan/O+LEbEXMJniS9aSJC11mgm2C8svZ58CXEUxAfKplVYlSVInNXNX5C3l4gRgl2rLkSRp\nybQZbBHxFSDb2p6ZJ1dSkSRJS6C9HtukbqtCkqQu0l6wjQEGZOZCT7yOiFWB1yutSpKkTmrvdv+v\nArstYv1IOngemyRJPaW9YNs+M3/UemVm/hi/xyZJWkq1F2z92tkWXV2IJEldob1gmxYR27VeGRHb\nAq9UV5IkSZ0XmYu+oz8idqR44vW3gD+Wq0cARwIfy8z7qizszbltf9VAkrTs6dunudHCNoMNICJW\nB04ENi9XPQp8LTNfWOIKO2CwSZIadUmw9SSDTZLUqNlg84GgkqRaMdgkSbXSdLBFxApVFiJJUlfo\nMNgiYoeImAj8tXy/VUR8rfLKJEnqhGZ6bFcAo4BpAJn5CMW0WpIkLXWaCbZemflMq3XzqihGkqQl\n1cwTtJ+NiB2AjIjeFN9re6LasiRJ6pwOv8cWEUMphiN3L1f9CjghM1+usjC/xyZJauQXtCVJtdJs\nsHU4FBkR18A7QyYzj+5EXZIkVaqZa2y/aljuCxwAPFtNOZIkLZnFHoqMiF7APZm5czUlFRyKlCQ1\nqnKuyPWAYZ04TpKkyjVzjW06/7zG1oviIaNnVFmUJEmd1W6wRUQAWwHPl6vm59J6G6UkSXQwFFmG\n2B2ZOa98GWqSpKVaM9fYHo6IbSqvRJKkLtDmUGRE9MnMucA2wIMR8SQwCwiKzty23VSjJElNa+8a\n2wPAtsB+3VSLJElLrL1gC4DMfLKbapEkaYm1F2xDIuLktjZm5mUV1CNJ0hJpL9h6AwOguW96S5K0\nNGhzSq2IGN+TN4g4pZYkqVFXTKllT02S9K7TXrD9e7dVIUlSF2kz2DLzle4sRJKkrtCZ2f0lSVpq\nGWySpFox2CRJtWKwSZJqxWCTJNWKwSZJqhWDTZJUKwabJKlWDDZJUq0YbJKkWjHYJEm1YrBJkmrF\nYJMk1YrBJkmqFYNNklQrBpskqVYMNklSrRhskqRaMdgkSbVisEmSasVgkyTVisEmSaoVg02SVCsG\nmySpVgw2SVKtGGwC4MUXXuCoT36cA/b9EAfstw/XXfs9AB5/7DEOO/RgDj5wfw49+EAmTpjQw5VK\nXe+cs89k11124sD9Ry1Y94u7fs4B++3D1ptvzKOTJi60/7ev+SajPrgH++2zF+Pu+X13l6sOGGwC\noHef3pxy2hncfOsdjLnhB9x4w/U8+be/8ZXLLuGY447nhz/5Gced8Gkuv+ySni5V6nL7f/hAvvHN\nby20boMNNuQrX/0a243YfqH1T/7tb9x5x+385Jbb+fo3v8WFXziPefPmdWe56oDBJgCGDBnKJptu\nBkD//gMYPnw4U6dOIQhef30WAK+/9hpDhgztyTKlSmw3YntWGjRooXXD11+fddcb/o597/7NWD74\noX1YfvnlWWuttVl77fcwaaIjGUuTPj1dgJY+zz//HI8/9hhbbLkVp53xOY49+igu+5+LmD9/Pt+/\n7saeLk/qUVOmTGHLrbZa8H7Y6sOYOmVKD1ak1irpsUXExIiY0NarneOOjoiHIuKhb19zdRWlqQOz\nZ83is585iVPP+BwDBgzghz+4gVNPP5NfjP0tp55+Juf+91k9XaIktauqHlvLFdjjy/9eW/53dHsH\nZebVwNUAb84lqylNbZkzZw4nf+YkPrTPvuy+x54A3Pqzmzn9zCLM9txrb8475+yeLFHqccOGDWPK\niy8ueD/lxSkMHTasBytSa5X02DLzmcx8BtgjM0/LzInl6wxgzyra1JLJTM495yyGDx/O4Z88YsH6\nIUOH8tCDDwDwwB/uZ533rNtDFUpLhw+M3I0777idt99+m+eee5Z//ONpNt9iy54uSw0is7qOUUQ8\nDByfmePK9zsDX8/MrTs61h5b9xr/x4c44vDRvHfDDekVxb93TvzMyfTv35+Lv3wh8+bOZfkVVuCs\n//48m262eQ9XK3Wt0085mYcefIAZM6azyqqrcuzxJzJo0GC+fOEFTH/lFQautBIbbbQJ/3vNtwG4\n5pvf4Kc330Tv3r057YzP8W+7fKCHP8GyoW8fopn9qg627YD/AwYBAUwHjszM8R0da7BJkhotFcG2\noJGIQQCZ+WqzxxhskqRGzQZbpbf7R8Q5rd4DkJnnV9muJGnZVfX32GY1LPeluFvysYrblCQtw7pl\nKHJBYxErAHdl5q4d7etQpCSpUbNDkd09pdaKwFrd3KYkaRlS9TW2ibCg59UbGAJ4fU2SVJmqb/d/\nT8PbucCUzJzbzLEORUqSGi1tt/sPpbh5BIDM/EdHxxhskqRGS8U1tojYLyL+CjwF/BZ4Gvh5lW1K\nkpZtVd88cgGwI/BEZq4H/Dtwf8VtSpKWYVUH25zMnAb0iohemfkbYETFbUqSlmFVf0F7RkQMAH4H\nXBcRU1n4S9uSJHWpqu+K7A+8QdEzHE0xGfJ1ZS+uXd48Iklq1ON3RUZEb+BXmTmyM8cbbJKkRj1+\nV2RmzgPmt8zsL0lSd6j6GtvrwMSI+CUN19Yy86SK25UkLaOqDraflC9JkrpFJdfYImKdZmYXaY/X\n2CRJjXr6GttPWxYi4qaK2pAk6R2qCrbGVB1eURuSJL1DVcGWbSxLklSpqq6xzaO4CzKAfsDslk1A\nZuZKHZ3Da2ySpEbNXmOr5K7IzOxdxXklSepI1ZMgS5LUrQw2SVKtGGySpFox2CRJtWKwSZJqxWCT\nJNWKwSZJqhWDTZJUKwabJKlWDDZJUq0YbJKkWjHYJEm1YrBJkmrFYJMk1YrBJkmqFYNNklQrBpsk\nqVYMNklSrRhskqRaMdgkSbVisEmSasVgkyTVisEmSaoVg02SVCsGmySpVgw2SVKtGGySpFox2CRJ\ntWKwSZJqxWCTJNWKwSZJqpXIzJ6uQUuxiDg6M6/u6TqknubvwruHPTZ15OieLkBaSvi78C5hsEmS\nasVgkyTVisGmjnhNQSr4u/Au4c0jkqRasccmSaoVg02SVCsGW01EREbEpQ3vT4mIczs45sMRsWnD\n++9GxFMR8XD5OqmiWu+OiBFVnFvqSETMa/gZfzgi1q2gjXUjYlJXn1fN6dPTBajLvAUcGBFfysyX\nmzzmw8BtwJ8b1p2amT9u64CI6J2Z85agTqmnvZGZW7e1MSL6ZObc7ixIXcseW33Mpbhr679abyj/\n9fjriJgQEWMjYp2I2BnYD7ik/Ffr+m2dOCJej4hLI+IRYKeIOCciHoyISRFxdUREud+CnlhErBYR\nT5fL/SLixoh4LCJuBvp1+aeXlkBEfDIibomIXwNjI2JA+bsyPiImRsT+5X4L9cQaR0YiYruIeKT8\nPTm+Rz6IAIOtbq4CRkfEoFbrvwZ8LzO3BK4DrsjMe4FbKHpoW2fmk+W+LUH3cERsUa7rD/whM7fK\nzHuAKzNz+8zcnCKkRnVQ17HA7MzcBPg8sN0Sf1Kp8/o1/Izf3LB+W+CgzPwA8CZwQGZuC4wELm35\nB1w7vgOcmJlbVVO2muVQZI1k5syI+D5wEvBGw6adgAPL5WuBi9s5zaKGIucBNzW8HxkRpwErAqsA\njwK3tnPO9wNXlDVOiIgJHX0WqUJtDUX+MjNfKZcDuDAi3g/MB9YEhrV1wogYDAzOzN+Vq64F9u7C\nmrUYDLb6uRwYT/Gvx67yZst1tYjoC3wdGJGZz5bDMH3L/ebyz1GAvu84i7R0m9WwPBoYAmyXmXPK\nYfW+LPwzDv6cL5UciqyZ8l+cPwSOalh9L/DRcnk08Pty+TVg4GI20fKL/HJEDAAOatj2NP8cZmxc\n/zvgYwARsTmw5WK2KXW3QcDUMtRGAu8p108BhkbEqhGxAuUwfGbOAGZExL+V+43u9oq1gMFWT5cC\nqzW8PxE4ohwC/Djw6XL9jcCpEfGn9m4eaVT+Al8DTALuAh5s2Pw/wLER8adW7X8DGBARjwHnA39c\n/I8kdavrgBERMRE4HHgcIDPnUPwMPwD8smV96Qjgqoh4mGIoUz3EKbUkSbVij02SVCsGmySpVgw2\nSVKtGGySpFox2CRJtWKwSQ0aZn6fFBE/iogVl+Bcu0bEbeXyfhFxRjv7Do6I4zrRxrkRcUob2w4v\nP8fE8isdp5TrvxsRBy3qGKkODDZpYW+Uc2duDrwNHNO4MQqL/XuTmbdk5pfb2WUwsNjB1paI2Bv4\nDLBnZm4B7Ai82lXnl5ZmBpvUtt8DG5Qzuv+lnIdzErB2ROwZEfeVs7//qJyFhYj4YEQ8HhHj+ef8\nnC2zx19ZLg+LiJtbZoIvn7TwZWD9srd4SbnfqeVTFCZExHkN5zorIp6IiHuAjdqo/UzglMycDJCZ\nb2XmNa13audJDSdFxJ/Ltm8s132gYfLgP0XE4s5aI3UL54qUFiEi+lBMYntnueq9wCcy8/6IWA04\nG9g9M2dFxOnAyRFxMcWsLLsBfwN+0MbprwB+m5kHRERvYABwBrB5y+S8EbFn2eYOFLNY3FJOyDuL\nYnq0rSl+f8ez6JlcNm9jfWtXZub5ZZvXUkwRdWtZz3qZ+VY5wS/AKcDxmTmuDPI3mzi/1O3ssUkL\n61dOifQQ8A/g2+X6ZzLz/nJ5R2BTYFy57yco5hLcGHgqM/+axZQ+Y9poYzeKacbIzHmZuaghwj3L\n158owmtjiqDbBbg5M2dn5kyKRw8tiZER8Ydy6qjdgM3K9ROA6yLiMIqJfwHGAZdF8WT1wT6MU0sr\ne2zSwt7xSJNydK5x5vegeMTJoa32a/OpzJ0QwJcy85ut2vhMk8c/SjEh9a/bbKD9JzXsQ/G4oX2B\nsyJii8z8ckTcDnyIItT3yszHF3VuqSfZY5MW3/3A+yJiA4CI6B8RG1JMiLtuw4TSh7Zx/FiKh68S\nEb2jeDBs6yct3AUc2XDtbs2IGErxpIQPR/FU8oEUwbMoX6J4aOzq5fHLR8SnWu2zyCc1lDfHrJ2Z\nvwFOp5jpfkBErJ+ZEzPzIorJrzdu7w9J6in22KTFlJkvRcQngRvKR5cAnJ2ZT0TE0cDtETGb4uaT\nRd1g8Wng6og4iuIhrsdm5n0RMS4iJgE/z8xTI2IT4L6yx/g6cFhmjo+IHwCPAFNZ+OkKjTXeERHD\ngF+VN4Qk8H+t9pkRES1Panix4Vy9gTFl4AbFE9dnRMQFUTzCZT5Fj/Dni/lHJ3ULZ/eXJNWKQ5GS\npFox2CRJtWKwSZJqxWCTJNWKwSZJqhWDTZJUKwabJKlW/j+lFXQod9cUFwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg8M6QB3rxoh",
        "colab_type": "text"
      },
      "source": [
        "В логистической регрессии (и её обобщениях – нейросетях) баланс классов сильно влияет на свободный член, но очень слабо – на коэффициенты наклона. Действительно, предсказанное отношение шансов  из бинарной логистической регрессии меняется на константу при изменении баланса классов, и этот эффект уходит в свободный член.\n",
        "\n",
        "\n",
        "В деревьях решений (и их обобщениях – случайном лесе и градиентном бустинге), дисбаланс классов влияет на меры неоднородности (impurity) листьев, но это влияние примерно пропорционально для всех кандидатов в очередную разбивку (split), и потому обычно не особо влияет на выбор разбивок.\n",
        "\n",
        "\n",
        "С другой стороны, на не-вероятностные модели типа SVM дисбаланс классов может серьёзно влиять. SVM строит обучающую гиперплоскость так, что примерно одно и то же число положительных и отрицательных примеров находится на разделяющей полосе или на неправильной её стороне. Поэтому изменение баланса классов может повлиять это число, а значит, и на положение границы.\n",
        "\n",
        "\n",
        "Когда мы используем вероятностные модели для бинарной классификации, всё ОК: во время обучения, модели не сильно зависят от баланса классов, а при тестировании мы можем использовать метрики, нечувствительные к балансу классов. Такие метрики (например, ROC AUC) зависят от предсказанных вероятностей классов, а не от «жёсткой» дискретной классификации.\n",
        "\n",
        "Источник: https://habr.com/ru/post/349078/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOeedR3Urxop",
        "colab_type": "text"
      },
      "source": [
        "To-do:\n",
        "Мы разработали классификатор, основанный на алгоритме случайнго леса решающих деревьев, хоть он и не так чувствителен к дисбалансу классов как логистическая регрессия или нейронная сеть (по причинам описанным выше), точность его работы можно попробовать увеличить. Мы использовали случайный лес на минималках, можно попробовать поиграться с гипер-параметрами алгоритма для улучшения его работы.\n",
        "Увеличение значений гипер параметров (количество деревьев,глубина... в документации sklearn можно посмотреть полный перечень https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) ведет к усложнению архитектуры модели, что в свою очередь может привести к переобучению, для этого было бы неплохо провести процесс регуляризации и подбора оптимальных гипер-параметров, данный процесс хорошо и наглядно описан в одном из занятий курса ODS https://habr.com/ru/company/ods/blog/324402/."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMDSm95x-Rhb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "cb924700-e330-4365-a043-849cdb01676e"
      },
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "#обучаем модель изолированного леса на полной тренировочной выборке\n",
        "Model_IForest_RandSeed = np.random.RandomState(40)\n",
        "\n",
        "Model_IForest = IsolationForest(random_state = Model_IForest_RandSeed,\n",
        "                                   n_estimators=10, bootstrap=True, behaviour='new')\n",
        "Model_IForest.fit(XTrain,YTrain)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IsolationForest(behaviour='new', bootstrap=True, contamination='legacy',\n",
              "                max_features=1.0, max_samples='auto', n_estimators=10,\n",
              "                n_jobs=None,\n",
              "                random_state=<mtrand.RandomState object at 0x7fb4925d3e10>,\n",
              "                verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6jZ_e_f-S3O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "8accc5b3-c600-421e-e611-993b010ff0dc"
      },
      "source": [
        "#проверим работоспособность нашего классификатора на тестовой выборке\n",
        "Pred = Model_IForest.predict(XTest)\n",
        "print(classification_report(YTest,Pred,digits=5))\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1    0.00000   0.00000   0.00000         0\n",
            "           0    0.00000   0.00000   0.00000     85305\n",
            "           1    0.00043   0.23913   0.00086       138\n",
            "\n",
            "    accuracy                        0.00039     85443\n",
            "   macro avg    0.00014   0.07971   0.00029     85443\n",
            "weighted avg    0.00000   0.00039   0.00000     85443\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}