{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем данные\n",
    "\n",
    "* Данные по кампаниям за 1 год\n",
    "* **5369** кампаний\n",
    "* **64** параметра\n",
    "* Параметры рассчитывались за **0,1,2 и 3 дни** жизни пользователя\n",
    "* Нужно прогнозировать **CARPU 60 дня**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv('data_campaigns.csv',delimiter =',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исключим мелкие когорты (< 75 квантили)(А что будет, если не будем исключать?)\n",
    "cohort_size=data[\"size\"].quantile(0.75)\n",
    "data=data[data['size']>=cohort_size].reset_index(drop=True)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (!) Пропущенные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сколько у нас пропущенных значений?\n",
    "missing = (data.isnull().sum() / len(data)) * 100\n",
    "missing = missing.drop(missing[missing==0].index).sort_values(ascending=False)\n",
    "missing = pd.DataFrame({'Missing Ratio': missing})\n",
    "missing.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполним пропущенные значения и проверим\n",
    "data.fillna(0, inplace = True)\n",
    "\n",
    "missing = (data.isnull().sum() / len(data)) * 100\n",
    "missing = missing.drop(missing[missing==0].index).sort_values(ascending=False)\n",
    "missing = pd.DataFrame({'Missing Ratio': missing})\n",
    "missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим X и y\n",
    "X = data.iloc[:,1:65]\n",
    "y = data['y_target']\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (!) Нормализация (трансформация Бокса-Кокса), коэффициент асимметрии и логарифмирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализуем X трансформацией Бокса-Кокса\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import skew\n",
    "import numpy as np\n",
    "\n",
    "numeric_feats = X.dtypes[X.dtypes!=\"object\"].index\n",
    "skewed_feats = X[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending = False)\n",
    "skewness = pd.DataFrame({'Skew':skewed_feats})\n",
    "skewness = skewness[abs(skewness)>0.2]\n",
    "skewed_features = skewness.index\n",
    "lam=0.04\n",
    "for feat in skewed_features:\n",
    "    X[feat] = boxcox1p(X[feat],lam)\n",
    "\n",
    "# Логарифмируем target и смотрим коэффициент асимметрии. Для реальных результатов незабываем потенциировать\n",
    "y_n=boxcox1p(y,0)\n",
    "print(\"Коэффициент ассиметрии y до транфсормации – %s, b и после – %s\"% (skew(y),skew(y_n)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_n.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (!) Robust и Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабируем с Robust Scaler-ом (median/IQR, а не mean/variance)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "sc = RobustScaler()\n",
    "names = list(X.columns)\n",
    "X= sc.fit_transform(X)\n",
    "X = pd.DataFrame(data=X, columns=names)\n",
    "X.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перейдем к моделированию\n",
    "* **(!) Модель:** Будем использовать Ridge regression\n",
    "* **(!) Кросс-валидация**: алгоритм ShuffleSplit\n",
    "* **Работа с параметрами:** Pearson score, RFECV\n",
    "* **Регуляризация**. Посмотрим как выбирается параметр Alpha\n",
    "* **Learning Curve**: Посмотрим как ведет себя модель на обучающей и валидирующей выборках\n",
    "* **Residuals Plot**: Посмотрим как ведут себя остатки (разница между реальным и пронозным значениями)\n",
    "* **Prediction Error Plot**: Сравним прогнозные результаты модели с ее реальными значениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import  RidgeCV\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split\n",
    "\n",
    "\n",
    "cv=ShuffleSplit(n_splits=10,train_size=0.8,test_size=0.2,random_state= 2019)\n",
    "alphas = np.logspace(-4, 1, 50)\n",
    "regressor = RidgeCV(alphas=alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (!) Смотрим R2 и MSE + yellowbrick framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from yellowbrick.model_selection import CVScores\n",
    "\n",
    "_, ax = plt.subplots(figsize=(10,10))\n",
    "r2 = CVScores(regressor,ax=ax,cv=cv,scoring='r2')\n",
    "r2.fit(X,y_n)\n",
    "r2.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10,10))\n",
    "mse = CVScores(regressor,ax=ax,cv=cv,scoring='neg_mean_squared_error')\n",
    "mse.fit(X,y_n)\n",
    "mse.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим как ведет себя RMSE\n",
    "from sklearn.metrics import make_scorer\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(np.mean((y_pred - y)**2))\n",
    "\n",
    "scorer = make_scorer(rmse,greater_is_better=False)\n",
    "\n",
    "_, ax = plt.subplots(figsize=(10,10))\n",
    "mse = CVScores(regressor,ax=ax,cv=cv,scoring=scorer)\n",
    "mse.fit(X,y_n)\n",
    "mse.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_n.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (!) Посмотрим на возможные выбросы (обычный МНК, расстояние Кука)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import OLS\n",
    "\n",
    "m = OLS(y_n,X).fit()\n",
    "infl = m.get_influence()\n",
    "sm_fr = infl.summary_frame()\n",
    "_, ax = plt.subplots(figsize=(20,10))\n",
    "plt.plot(sm_fr['cooks_d'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_out=X.drop(sm_fr['cooks_d'][sm_fr['cooks_d']>4/len(X)].index)\n",
    "y_out=y_n.drop(sm_fr['cooks_d'][sm_fr['cooks_d']>4/len(X)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = OLS(y_out,X_out).fit()\n",
    "infl = m.get_influence()\n",
    "sm_fr = infl.summary_frame()\n",
    "_, ax = plt.subplots(figsize=(20,10))\n",
    "plt.plot(sm_fr['cooks_d'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_out=X_out.drop(sm_fr['cooks_d'][sm_fr['cooks_d']>4/len(X)].index)\n",
    "y_out=y_out.drop(sm_fr['cooks_d'][sm_fr['cooks_d']>4/len(X)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = OLS(y_out,X_out).fit()\n",
    "infl = m.get_influence()\n",
    "sm_fr = infl.summary_frame()\n",
    "_, ax = plt.subplots(figsize=(20,10))\n",
    "plt.plot(sm_fr['cooks_d'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (!) Поработаем с параметрами (корреляционная матрица)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим коллеряционную матрицу\n",
    "from yellowbrick.features import Rank2D,RFECV\n",
    "_, ax = plt.subplots(figsize=(20,10))\n",
    "rank = Rank2D(ax=ax,features=names,algorithm='pearson')\n",
    "rank.fit(X_out,y_out)\n",
    "rank.transform(X)\n",
    "rank.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (!) Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Попробуем посмотреть Recursive Feature Elimination\n",
    "_, ax = plt.subplots(figsize=(20,10))\n",
    "rfe = RFECV(regressor,cv=cv,scoring=scorer,step=10)\n",
    "rfe.fit(X_out,y_out)\n",
    "rfe.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохраним выбранные параметры\n",
    "params = {\n",
    "    'parameters': list(X.columns),\n",
    "    'ranking':list(rfe.ranking_)\n",
    "}\n",
    "par = pd.DataFrame(data=params)\n",
    "huber_params = list(par[par['ranking']==1]['parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим корреляционную матрицу еще раз\n",
    "_, ax = plt.subplots(figsize=(20,10))\n",
    "rank = Rank2D(ax=ax,features=huber_params,algorithm='pearson')\n",
    "rank.fit(X_out[huber_params],y_n)\n",
    "rank.transform(X_out[huber_params])\n",
    "rank.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (!) Регуляризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import AlphaSelection\n",
    "_, ax = plt.subplots(figsize=(20,10))\n",
    "a_select=AlphaSelection(RidgeCV(alphas=alphas))\n",
    "a_select.fit(X_out[huber_params],y_out)\n",
    "a_select.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.model_selection import LearningCurve\n",
    "sizes = np.linspace(0.2, 1.0, 5)\n",
    "_, ax = plt.subplots(figsize=(20,10))\n",
    "lc = LearningCurve(RidgeCV(alphas=alphas), scoring=scorer,cv=cv)\n",
    "lc.fit(X_out[huber_params],y_out)\n",
    "lc.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(20,10))\n",
    "lc = LearningCurve(RidgeCV(alphas=alphas), scoring='r2',cv=cv)\n",
    "lc.fit(X_out[huber_params],y_out)\n",
    "lc.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим, что нам дает обученная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Смотрим как ведут себя остатки\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yellowbrick.regressor import ResidualsPlot,PredictionError\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_out[huber_params],y_out,test_size=0.2,random_state=2019)\n",
    "regressor=RidgeCV(alphas=alphas,cv=cv,scoring=scorer)\n",
    "\n",
    "_, ax = plt.subplots(figsize=(20,10))\n",
    "res = ResidualsPlot(regressor)\n",
    "res.fit(X_train,y_train)\n",
    "res.score(X_test,y_test)\n",
    "res.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Смотрим как распределены ошибки\n",
    "_, ax = plt.subplots(figsize=(20,10))\n",
    "error=PredictionError(regressor)\n",
    "error.fit(X_train,y_train)\n",
    "error.score(X_test,y_test)\n",
    "error.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10,10))\n",
    "mse = CVScores(regressor,ax=ax,cv=cv,scoring=scorer)\n",
    "mse.fit(X_out[huber_params],y_out)\n",
    "mse.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В итоге\n",
    "* R2 ≈ **?**\n",
    "* ln(RMSE) ≈ **?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
